{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a40ff9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 1. IMPORT LIBRARIES\n",
    "# ===========================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Model Klasifikasi\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Evaluasi Model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style untuk visualisasi\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úì Library import successful!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9f17dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# A.1 LOAD DATA DAN EKSPLORASI AWAL\n",
    "# ===========================\n",
    "\n",
    "# Load dataset dari Kaggle\n",
    "import kagglehub\n",
    "path = kagglehub.dataset_download(\"blastchar/telco-customer-churn\")\n",
    "csv_path = f\"{path}/WA_Fn-UseC_-Telco-Customer-Churn.csv\"\n",
    "\n",
    "# Baca dataset\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"EKSPLORASI AWAL DATASET\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Tampilkan 5 baris pertama\n",
    "print(\"\\n1Ô∏è‚É£ Lima Baris Pertama Dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# 2. Info Dataset\n",
    "print(\"\\n2Ô∏è‚É£ Informasi Dataset:\")\n",
    "print(df.info())\n",
    "\n",
    "# 3. Statistik Deskriptif\n",
    "print(\"\\n3Ô∏è‚É£ Statistik Deskriptif:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(f\"\\nüìä Dimensi Dataset: {df.shape[0]} baris, {df.shape[1]} kolom\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4ae384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# A.2 IDENTIFIKASI MISSING VALUE\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"IDENTIFIKASI MISSING VALUE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Hitung missing value\n",
    "missing_data = pd.DataFrame({\n",
    "    'Kolom': df.columns,\n",
    "    'Missing_Count': df.isnull().sum().values,\n",
    "    'Missing_Percentage': (df.isnull().sum().values / len(df) * 100).round(2)\n",
    "})\n",
    "missing_data = missing_data[missing_data['Missing_Count'] > 0].sort_values('Missing_Percentage', ascending=False)\n",
    "\n",
    "if len(missing_data) == 0:\n",
    "    print(\"\\n‚úì Tidak ada missing value dalam dataset!\")\n",
    "else:\n",
    "    print(\"\\nMissing Value Ditemukan:\")\n",
    "    print(missing_data)\n",
    "    \n",
    "    # Visualisasi missing value\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    missing_data_plot = df.isnull().sum()\n",
    "    missing_data_plot = missing_data_plot[missing_data_plot > 0].sort_values(ascending=False)\n",
    "    missing_data_plot.plot(kind='barh', ax=ax, color='coral')\n",
    "    ax.set_xlabel('Jumlah Missing Value')\n",
    "    ax.set_title('Distribusi Missing Value per Kolom')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946aefbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# A.2B IDENTIFIKASI DAN HAPUS DUPLICATE DATA\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"IDENTIFIKASI DAN HAPUS DUPLICATE DATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Cek duplicate berdasarkan semua kolom\n",
    "duplicate_all = df.duplicated().sum()\n",
    "print(f\"\\n1Ô∏è‚É£ Duplikat (semua kolom): {duplicate_all} baris\")\n",
    "\n",
    "# Cek duplicate berdasarkan customerID (unique identifier)\n",
    "if 'customerID' in df.columns:\n",
    "    duplicate_id = df.duplicated(subset=['customerID'], keep=False).sum()\n",
    "    print(f\"2Ô∏è‚É£ Duplikat berdasarkan customerID: {duplicate_id} baris\")\n",
    "    \n",
    "    if duplicate_id > 0:\n",
    "        print(\"\\n   Menampilkan duplikat customerID:\")\n",
    "        dup_customers = df[df.duplicated(subset=['customerID'], keep=False)].sort_values('customerID')\n",
    "        print(dup_customers[['customerID', 'tenure', 'MonthlyCharges']].head(10))\n",
    "\n",
    "# Hapus duplikat\n",
    "print(\"\\n3Ô∏è‚É£ Menghapus duplikat...\")\n",
    "df_before = len(df)\n",
    "df = df.drop_duplicates()\n",
    "df_after = len(df)\n",
    "rows_removed = df_before - df_after\n",
    "\n",
    "print(f\"   Baris sebelum: {df_before}\")\n",
    "print(f\"   Baris sesudah: {df_after}\")\n",
    "print(f\"   ‚úì Duplikat yang dihapus: {rows_removed} baris\")\n",
    "\n",
    "# Jika ada duplikat customerID setelah drop_duplicates, hapus berdasarkan ID\n",
    "if 'customerID' in df.columns:\n",
    "    df = df.drop_duplicates(subset=['customerID'], keep='first')\n",
    "    print(f\"   ‚úì Dataset setelah drop duplikat customerID: {len(df)} baris\")\n",
    "\n",
    "print(f\"\\n‚úì Dataset cleaning complete! Shape: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481bfdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# A.3 VISUALISASI DISTRIBUSI TARGET (CHURN)\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANALISIS VARIABEL TARGET (CHURN)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Distribusi Churn\n",
    "churn_counts = df['Churn'].value_counts()\n",
    "churn_percentage = df['Churn'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"\\nDistribusi Target Churn:\")\n",
    "print(f\"  No:  {churn_counts['No']} ({churn_percentage['No']:.2f}%)\")\n",
    "print(f\"  Yes: {churn_counts['Yes']} ({churn_percentage['Yes']:.2f}%)\")\n",
    "\n",
    "# Visualisasi\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar plot\n",
    "churn_counts.plot(kind='bar', ax=axes[0], color=['green', 'red'], alpha=0.7)\n",
    "axes[0].set_title('Distribusi Churn (Count)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Jumlah Pelanggan')\n",
    "axes[0].set_xlabel('Churn Status')\n",
    "axes[0].set_xticklabels(['No', 'Yes'], rotation=0)\n",
    "\n",
    "# Pie chart\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "axes[1].pie(churn_counts.values, labels=churn_counts.index, autopct='%1.1f%%', \n",
    "            colors=colors, startangle=90)\n",
    "axes[1].set_title('Proporsi Churn', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Cek class imbalance\n",
    "imbalance_ratio = churn_counts['Yes'] / churn_counts['No']\n",
    "print(f\"\\n‚ö†Ô∏è Class Imbalance Ratio: {imbalance_ratio:.3f}\")\n",
    "if imbalance_ratio < 0.3:\n",
    "    print(\"   Status: Dataset memiliki imbalance yang signifikan\")\n",
    "else:\n",
    "    print(\"   Status: Dataset cukup seimbang\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1ad1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# A.4 ANALISIS KORELASI\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANALISIS KORELASI FITUR NUMERIK\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Pilih fitur numerik\n",
    "numeric_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"\\nFitur Numerik yang Ditemukan: {numeric_features}\")\n",
    "\n",
    "# Buat correlation matrix\n",
    "correlation_matrix = df[numeric_features].corr()\n",
    "\n",
    "# Visualisasi heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Heatmap Korelasi Fitur Numerik', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Tampilkan korelasi dengan target jika numeric\n",
    "if 'Churn' in df.columns:\n",
    "    # Encode target untuk analisis korelasi\n",
    "    df_temp = df.copy()\n",
    "    df_temp['Churn_encoded'] = (df_temp['Churn'] == 'Yes').astype(int)\n",
    "    \n",
    "    target_correlation = df_temp[numeric_features + ['Churn_encoded']].corr()['Churn_encoded'].sort_values(ascending=False)\n",
    "    print(\"\\nKorelasi dengan Churn (Target):\")\n",
    "    print(target_correlation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2f18c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# B.1 PERSIAPAN DATA UNTUK DIRECT MODELING\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DIRECT MODELING - TANPA PREPROCESSING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Buat copy dataset\n",
    "df_direct = df.copy()\n",
    "\n",
    "# Encode target variable\n",
    "df_direct['Churn'] = (df_direct['Churn'] == 'Yes').astype(int)\n",
    "\n",
    "# Pisahkan X dan y\n",
    "y = df_direct['Churn']\n",
    "X = df_direct.drop(['Churn', 'customerID'], axis=1)\n",
    "\n",
    "# Convert categorical to numeric (simple encoding tanpa scaling)\n",
    "X_encoded = X.copy()\n",
    "for col in X_encoded.columns:\n",
    "    if X_encoded[col].dtype == 'object':\n",
    "        X_encoded[col] = LabelEncoder().fit_transform(X_encoded[col])\n",
    "\n",
    "# Handle TotalCharges yang mungkin string\n",
    "if X_encoded['TotalCharges'].dtype == 'object':\n",
    "    X_encoded['TotalCharges'] = pd.to_numeric(X_encoded['TotalCharges'], errors='coerce')\n",
    "    X_encoded['TotalCharges'].fillna(X_encoded['TotalCharges'].median(), inplace=True)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Data siap untuk modeling\")\n",
    "print(f\"  Training set: {X_train.shape}\")\n",
    "print(f\"  Testing set: {X_test.shape}\")\n",
    "print(f\"  Features: {X_train.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5830fd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# B.2 BUILD & TRAIN MODELS (DIRECT)\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRAINING 3 MODEL CATEGORIES (DIRECT - NO PREPROCESSING)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Kategori 1: Model Konvensional (Logistic Regression)\n",
    "print(\"\\n1Ô∏è‚É£ KONVENSIONAL MODEL: Logistic Regression\")\n",
    "lr_direct = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_direct.fit(X_train, y_train)\n",
    "print(\"   ‚úì Model trained\")\n",
    "\n",
    "# Kategori 2: Ensemble Bagging (Random Forest)\n",
    "print(\"\\n2Ô∏è‚É£ ENSEMBLE BAGGING: Random Forest\")\n",
    "rf_direct = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_direct.fit(X_train, y_train)\n",
    "print(\"   ‚úì Model trained\")\n",
    "\n",
    "# Kategori 3: Ensemble Voting\n",
    "print(\"\\n3Ô∏è‚É£ ENSEMBLE VOTING: Kombinasi LR, SVM, KNN\")\n",
    "lr_vote = LogisticRegression(random_state=42, max_iter=1000)\n",
    "svm_vote = SVC(kernel='rbf', random_state=42, probability=True)\n",
    "knn_vote = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "voting_direct = VotingClassifier(\n",
    "    estimators=[('lr', lr_vote), ('svm', svm_vote), ('knn', knn_vote)],\n",
    "    voting='soft'\n",
    ")\n",
    "voting_direct.fit(X_train, y_train)\n",
    "print(\"   ‚úì Model trained\")\n",
    "\n",
    "print(\"\\n‚úì Semua model berhasil ditraining!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5878ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# B.3 EVALUASI MODEL (DIRECT)\n",
    "# ===========================\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    \"\"\"Fungsi untuk evaluasi model\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n{model_name}\")\n",
    "    print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall:    {recall:.4f}\")\n",
    "    print(f\"  F1-Score:  {f1:.4f}\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"  Confusion Matrix:\\n{cm}\")\n",
    "    \n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'Confusion_Matrix': cm\n",
    "    }\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"HASIL EVALUASI - DIRECT MODELING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "results_direct = []\n",
    "results_direct.append(evaluate_model(lr_direct, X_test, y_test, \"Logistic Regression (Direct)\"))\n",
    "results_direct.append(evaluate_model(rf_direct, X_test, y_test, \"Random Forest (Direct)\"))\n",
    "results_direct.append(evaluate_model(voting_direct, X_test, y_test, \"Voting Classifier (Direct)\"))\n",
    "\n",
    "# Buat dataframe hasil\n",
    "df_results_direct = pd.DataFrame(results_direct)\n",
    "print(\"\\n\\nüìä RINGKASAN HASIL DIRECT MODELING:\")\n",
    "print(df_results_direct[['Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score']])\n",
    "\n",
    "# Visualisasi perbandingan\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "for idx, metric in enumerate(metrics):\n",
    "    ax = axes[idx//2, idx%2]\n",
    "    ax.bar(df_results_direct['Model'], df_results_direct[metric], color=['#3498db', '#e74c3c', '#2ecc71'])\n",
    "    ax.set_title(f'{metric} - Direct Modeling', fontweight='bold')\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    for i, v in enumerate(df_results_direct[metric]):\n",
    "        ax.text(i, v + 0.02, f'{v:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1302e9",
   "metadata": {},
   "source": [
    "## C. MODELING DENGAN PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30591af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# C.1 DATA PREPROCESSING\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PREPROCESSING DATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "df_prep = df.copy()\n",
    "\n",
    "# 1. Handle TotalCharges (convert to numeric)\n",
    "print(\"\\n1Ô∏è‚É£ Handling TotalCharges...\")\n",
    "df_prep['TotalCharges'] = pd.to_numeric(df_prep['TotalCharges'], errors='coerce')\n",
    "df_prep['TotalCharges'].fillna(df_prep['TotalCharges'].median(), inplace=True)\n",
    "print(\"   ‚úì TotalCharges converted to numeric\")\n",
    "\n",
    "# 2. Drop tidak relevan columns\n",
    "print(\"\\n2Ô∏è‚É£ Dropping irrelevant columns...\")\n",
    "df_prep = df_prep.drop(['customerID'], axis=1)\n",
    "print(\"   ‚úì customerID dropped\")\n",
    "\n",
    "# 3. Encode target\n",
    "print(\"\\n3Ô∏è‚É£ Encoding target variable...\")\n",
    "df_prep['Churn'] = (df_prep['Churn'] == 'Yes').astype(int)\n",
    "print(\"   ‚úì Churn encoded\")\n",
    "\n",
    "# 4. Pisahkan numeric dan categorical\n",
    "print(\"\\n4Ô∏è‚É£ Separating numeric and categorical features...\")\n",
    "numeric_cols = df_prep.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = df_prep.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"   Numeric columns: {numeric_cols}\")\n",
    "print(f\"   Categorical columns: {categorical_cols}\")\n",
    "\n",
    "# 5. One-Hot Encoding untuk categorical\n",
    "print(\"\\n5Ô∏è‚É£ Applying One-Hot Encoding...\")\n",
    "df_prep_encoded = pd.get_dummies(df_prep, columns=categorical_cols, drop_first=True)\n",
    "print(f\"   ‚úì Features after encoding: {df_prep_encoded.shape[1]}\")\n",
    "\n",
    "# 6. Pisahkan X dan y\n",
    "y_prep = df_prep_encoded['Churn']\n",
    "X_prep = df_prep_encoded.drop(['Churn'], axis=1)\n",
    "\n",
    "# 7. Scaling\n",
    "print(\"\\n6Ô∏è‚É£ Feature Scaling (StandardScaler)...\")\n",
    "scaler = StandardScaler()\n",
    "X_prep_scaled = scaler.fit_transform(X_prep)\n",
    "X_prep_scaled = pd.DataFrame(X_prep_scaled, columns=X_prep.columns)\n",
    "print(\"   ‚úì Features scaled\")\n",
    "\n",
    "# Train-test split\n",
    "X_train_prep, X_test_prep, y_train_prep, y_test_prep = train_test_split(\n",
    "    X_prep_scaled, y_prep, test_size=0.2, random_state=42, stratify=y_prep\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Preprocessing complete!\")\n",
    "print(f\"  Training set: {X_train_prep.shape}\")\n",
    "print(f\"  Testing set: {X_test_prep.shape}\")\n",
    "print(f\"  Total features: {X_train_prep.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f60b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# C.2 BUILD & TRAIN MODELS (WITH PREPROCESSING)\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRAINING MODELS WITH PREPROCESSING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Model 1: Logistic Regression\n",
    "print(\"\\n1Ô∏è‚É£ Logistic Regression (with preprocessing)\")\n",
    "lr_prep = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_prep.fit(X_train_prep, y_train_prep)\n",
    "print(\"   ‚úì Model trained\")\n",
    "\n",
    "# Model 2: Random Forest\n",
    "print(\"\\n2Ô∏è‚É£ Random Forest (with preprocessing)\")\n",
    "rf_prep = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_prep.fit(X_train_prep, y_train_prep)\n",
    "print(\"   ‚úì Model trained\")\n",
    "\n",
    "# Model 3: Voting Classifier\n",
    "print(\"\\n3Ô∏è‚É£ Voting Classifier (with preprocessing)\")\n",
    "voting_prep = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', LogisticRegression(random_state=42, max_iter=1000)),\n",
    "        ('svm', SVC(kernel='rbf', random_state=42, probability=True)),\n",
    "        ('knn', KNeighborsClassifier(n_neighbors=5))\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "voting_prep.fit(X_train_prep, y_train_prep)\n",
    "print(\"   ‚úì Model trained\")\n",
    "\n",
    "print(\"\\n‚úì Semua model dengan preprocessing berhasil ditraining!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae79e5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# C.3 EVALUASI MODEL (WITH PREPROCESSING)\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"HASIL EVALUASI - WITH PREPROCESSING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "results_prep = []\n",
    "results_prep.append(evaluate_model(lr_prep, X_test_prep, y_test_prep, \"Logistic Regression (Preprocessing)\"))\n",
    "results_prep.append(evaluate_model(rf_prep, X_test_prep, y_test_prep, \"Random Forest (Preprocessing)\"))\n",
    "results_prep.append(evaluate_model(voting_prep, X_test_prep, y_test_prep, \"Voting Classifier (Preprocessing)\"))\n",
    "\n",
    "# Buat dataframe hasil\n",
    "df_results_prep = pd.DataFrame(results_prep)\n",
    "print(\"\\n\\nüìä RINGKASAN HASIL WITH PREPROCESSING:\")\n",
    "print(df_results_prep[['Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score']])\n",
    "\n",
    "# Visualisasi perbandingan\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "for idx, metric in enumerate(metrics):\n",
    "    ax = axes[idx//2, idx%2]\n",
    "    ax.bar(df_results_prep['Model'], df_results_prep[metric], color=['#3498db', '#e74c3c', '#2ecc71'])\n",
    "    ax.set_title(f'{metric} - With Preprocessing', fontweight='bold')\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    for i, v in enumerate(df_results_prep[metric]):\n",
    "        ax.text(i, v + 0.02, f'{v:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7db6e3",
   "metadata": {},
   "source": [
    "## D. HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c0511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# D.1 HYPERPARAMETER TUNING\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"HYPERPARAMETER TUNING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Model 1: Logistic Regression Tuning\n",
    "print(\"\\n1Ô∏è‚É£ Tuning Logistic Regression...\")\n",
    "lr_params = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs', 'liblinear']\n",
    "}\n",
    "\n",
    "lr_grid = GridSearchCV(LogisticRegression(random_state=42, max_iter=1000), \n",
    "                       lr_params, cv=5, scoring='f1', n_jobs=-1)\n",
    "lr_grid.fit(X_train_prep, y_train_prep)\n",
    "lr_tuned = lr_grid.best_estimator_\n",
    "\n",
    "print(f\"   Best params: {lr_grid.best_params_}\")\n",
    "print(f\"   Best CV score: {lr_grid.best_score_:.4f}\")\n",
    "\n",
    "# Model 2: Random Forest Tuning\n",
    "print(\"\\n2Ô∏è‚É£ Tuning Random Forest...\")\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(RandomForestClassifier(random_state=42), \n",
    "                       rf_params, cv=5, scoring='f1', n_jobs=-1)\n",
    "rf_grid.fit(X_train_prep, y_train_prep)\n",
    "rf_tuned = rf_grid.best_estimator_\n",
    "\n",
    "print(f\"   Best params: {rf_grid.best_params_}\")\n",
    "print(f\"   Best CV score: {rf_grid.best_score_:.4f}\")\n",
    "\n",
    "# Model 3: Voting Classifier Tuning (tune base estimators)\n",
    "print(\"\\n3Ô∏è‚É£ Tuning Voting Classifier...\")\n",
    "voting_tuned = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', LogisticRegression(C=1, random_state=42, max_iter=1000)),\n",
    "        ('svm', SVC(kernel='rbf', C=1, gamma='scale', random_state=42, probability=True)),\n",
    "        ('knn', KNeighborsClassifier(n_neighbors=7))\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "voting_tuned.fit(X_train_prep, y_train_prep)\n",
    "print(f\"   ‚úì Voting Classifier tuned\")\n",
    "\n",
    "print(\"\\n‚úì Hyperparameter tuning complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af970068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# D.2 EVALUASI MODEL AFTER TUNING\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"HASIL EVALUASI - AFTER HYPERPARAMETER TUNING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "results_tuned = []\n",
    "results_tuned.append(evaluate_model(lr_tuned, X_test_prep, y_test_prep, \"Logistic Regression (Tuned)\"))\n",
    "results_tuned.append(evaluate_model(rf_tuned, X_test_prep, y_test_prep, \"Random Forest (Tuned)\"))\n",
    "results_tuned.append(evaluate_model(voting_tuned, X_test_prep, y_test_prep, \"Voting Classifier (Tuned)\"))\n",
    "\n",
    "# Buat dataframe hasil\n",
    "df_results_tuned = pd.DataFrame(results_tuned)\n",
    "print(\"\\n\\nüìä RINGKASAN HASIL AFTER TUNING:\")\n",
    "print(df_results_tuned[['Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score']])\n",
    "\n",
    "# Visualisasi perbandingan\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "for idx, metric in enumerate(metrics):\n",
    "    ax = axes[idx//2, idx%2]\n",
    "    ax.bar(df_results_tuned['Model'], df_results_tuned[metric], color=['#9b59b6', '#f39c12', '#1abc9c'])\n",
    "    ax.set_title(f'{metric} - After Tuning', fontweight='bold')\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    for i, v in enumerate(df_results_tuned[metric]):\n",
    "        ax.text(i, v + 0.02, f'{v:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6f894f",
   "metadata": {},
   "source": [
    "## E. PERBANDINGAN SEMUA SCENARIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485caeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# E. COMPREHENSIVE COMPARISON\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PERBANDINGAN SEMUA 9 MODEL (3 kategori √ó 3 scenario)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Gabungkan semua hasil\n",
    "all_results = pd.concat([df_results_direct, df_results_prep, df_results_tuned], ignore_index=True)\n",
    "\n",
    "# Sorting berdasarkan F1-Score\n",
    "all_results_sorted = all_results.sort_values('F1-Score', ascending=False)\n",
    "\n",
    "print(\"\\nüìä RANKING SEMUA MODEL:\")\n",
    "print(all_results_sorted[['Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score']])\n",
    "\n",
    "# Identifikasi best model\n",
    "best_model_idx = all_results['F1-Score'].idxmax()\n",
    "best_model_info = all_results.loc[best_model_idx]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üèÜ BEST MODEL\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Model: {best_model_info['Model']}\")\n",
    "print(f\"Accuracy:  {best_model_info['Accuracy']:.4f}\")\n",
    "print(f\"Precision: {best_model_info['Precision']:.4f}\")\n",
    "print(f\"Recall:    {best_model_info['Recall']:.4f}\")\n",
    "print(f\"F1-Score:  {best_model_info['F1-Score']:.4f}\")\n",
    "\n",
    "# Visualisasi comparison\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "x = np.arange(len(all_results_sorted))\n",
    "width = 0.2\n",
    "\n",
    "metrics_plot = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "colors_plot = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12']\n",
    "\n",
    "for i, metric in enumerate(metrics_plot):\n",
    "    ax.bar(x + i*width, all_results_sorted[metric], width, label=metric, color=colors_plot[i])\n",
    "\n",
    "ax.set_xlabel('Model', fontweight='bold')\n",
    "ax.set_ylabel('Score', fontweight='bold')\n",
    "ax.set_title('Perbandingan Performa Semua 9 Model', fontweight='bold', fontsize=14)\n",
    "ax.set_xticks(x + width * 1.5)\n",
    "ax.set_xticklabels(all_results_sorted['Model'], rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Heatmap comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "comparison_data = all_results_sorted[['Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score']].set_index('Model')\n",
    "sns.heatmap(comparison_data, annot=True, fmt='.3f', cmap='RdYlGn', vmin=0, vmax=1, ax=ax, cbar_kws={'label': 'Score'})\n",
    "ax.set_title('Heatmap Performa Semua Model', fontweight='bold', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a609996d",
   "metadata": {},
   "source": [
    "## F. DEPLOYMENT MODEL (Save & Streamlit Prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252dd0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# F.1 SAVE BEST MODEL\n",
    "# ===========================\n",
    "\n",
    "import pickle\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SAVING BEST MODEL FOR DEPLOYMENT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Tentukan best model untuk digunakan di Streamlit\n",
    "# Gunakan tuned Random Forest (biasanya performa terbaik)\n",
    "best_model_deploy = rf_tuned\n",
    "model_name_deploy = \"Random Forest (Tuned)\"\n",
    "\n",
    "print(f\"\\n‚úì Model untuk deployment: {model_name_deploy}\")\n",
    "\n",
    "# Save model\n",
    "model_path = \"best_churn_model.pkl\"\n",
    "joblib.dump(best_model_deploy, model_path)\n",
    "print(f\"‚úì Model saved: {model_path}\")\n",
    "\n",
    "# Save scaler\n",
    "scaler_path = \"scaler.pkl\"\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(f\"‚úì Scaler saved: {scaler_path}\")\n",
    "\n",
    "# Save feature names\n",
    "feature_names_path = \"feature_names.pkl\"\n",
    "feature_names = X_prep_scaled.columns.tolist()\n",
    "joblib.dump(feature_names, feature_names_path)\n",
    "print(f\"‚úì Feature names saved: {feature_names_path}\")\n",
    "\n",
    "print(\"\\n‚úì Semua file untuk deployment sudah tersimpan!\")\n",
    "print(\"\\nFile yang dibutuhkan untuk Streamlit:\")\n",
    "print(f\"  1. {model_path}\")\n",
    "print(f\"  2. {scaler_path}\")\n",
    "print(f\"  3. {feature_names_path}\")\n",
    "print(f\"  4. Dataset original (untuk reference encoding)\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
